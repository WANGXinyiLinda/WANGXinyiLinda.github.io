---
layout: archive
permalink: /
hidden: true
author_profile: true
---

I'm a first year PhD student in the computer science department at the University of California, Santa Barbara (UCSB). I am glad to have professor [William Yang Wang](https://sites.cs.ucsb.edu/~william/index.html) as my advisor and I am interested in natural language processing and machine learning in general. I graduated from the Hong Kong University of Science and Technology (HKUST) in 2020 with a B.Sc. in applied mathematics and computer science. 
<!-- I was on exchange at the University of California, Los Angeles (UCLA) from September to December, 2019.  -->
<!-- I also had the fortune to work with [Yi Yang](http://yya518.github.io/) and [Prof. Yuan Yao](https://yao-lab.github.io/).  -->
<!-- \[[CV](/pdf/Resume.pdf)\]  -->

## Education 
* **University of California, Santa Barbara**, Oct 2020 - Present
  * Ph.D. in Computer Science

* **Hong Kong University of Science and Technology**, Sep 2016 - Jul 2020
  * B.Sc. in Applied Mathematics and Computer Science
  <!-- * CGA: 3.74/4.30  -->
  <!-- \[[transcript](/pdf/HKUST_transcript.pdf)\] -->
  <!-- * Capstone Project Supervisor: Prof. Yuan, Yao  -->

* **University of California, Los Angeles**, Sep 2019 - Dec 2019
  * Fall quater exchange
  <!-- * CGA: 3.90/4.00 (Dean's Honors List)  -->
  <!-- \[[transcript](/pdf/UCLA_transcript.pdf)\] -->

## Scholarships and Academic Honors

* Chern Class Talent Scholarship (2017 - 2020) from HKUST Math department
* Chern Class Achievement Scholarship (2020) from HKUST Math department
* The 15th Epsilon Fund Award (2020) from HKUST Math department
* Universityâ€™s Scholarship Scheme for Continuing Undergraduate Students (2017 - 2020) from HKUST
* Reaching Out Award (2019 - 2020) from HKSAR Government Scholarship Fund
* Joseph Needham Merit Scholarship (2020) from the Joseph Needham Foundation for Science & Civilisation (Hong Kong) 
* Academic Excellence Fellowship (2020) from UCSB

## Publications

* **Counterfactual Maximum Likelihood Estimation for Training Deep Networks** (arXiv preprint)

  **Xinyi Wang**, Wenhu Chen, Michael Saxon, William Yang Wang \[[paper](https://arxiv.org/abs/2106.03831)\]

* **Dimensions of Transparency in NLP Applications** (arXiv preprint)

  Michael Saxon, Sharon Levy, **Xinyi Wang**, Alon Albalak, William Yang Wang \[[paper](https://arxiv.org/abs/2101.00433)\]

* **RefBERT: Compressing BERT by Referencing to Pre-computed Representations** (to appear in IJCNN 2021, long paper, oral)

  **Xinyi Wang**\*, Haiqin Yang\*, Liang Zhao, Yang Mo and Jianping Shen

* **Neural Topic Model with Attention for Supervised Learning** (AISTATS 2020, long paper)

  **Xinyi Wang**, Yi Yang \[[paper](http://proceedings.mlr.press/v108/wang20c.html)\]

<!-- * **Direct Proof of the Formation of Droplet Surface Shape and the Principle of Minimizing Free Energy** (College Physics. Sep. 2020)

  Kang Jin, **Xinyi Wang**, Kaihang Gui -->